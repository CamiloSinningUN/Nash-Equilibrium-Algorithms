{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEMKE- HOWSON\n",
    "[Assignment 1] We focus on perturbations over payoffs. You are required to study how the equilibria of a game vary once some payoff of the matrix is perturbed. For instance, given the following game\n",
    "\n",
    "(1,1) (0,0)\n",
    "\n",
    "(0,0) (0,0)\n",
    "\n",
    "a perturbation can be:\n",
    "\n",
    "(1,1) (0,0)\n",
    "\n",
    "(0,0) (e,e)\n",
    "\n",
    "where e > 0 is arbitrarily close to zero. You will be required to understand how the best-response regions vary as perturbation e varies (in particular, studying the regions and their labels used by the Lemke-Howson algorithm) and how the set of equilibria changes (e.g., new equilibria may appear, some equilibria may collapse to a single equilibrium, some equilibria may disappear). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amplpy import AMPL\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AMPL\n",
    "ampl = AMPL()\n",
    "\n",
    "# Nash equilibrium function\n",
    "def nash_equilibrium(players, actions, **kwargs):\n",
    "    # AMPl for data\n",
    "    I = actions\n",
    "    P = players\n",
    "\n",
    "    U = {player: kwargs['U' + str(player)] for player in P}\n",
    "    \n",
    "    # AMPL for model\n",
    "    ampl.eval(r\"\"\"\n",
    "        set P; # Players\n",
    "        set I; # Actions\n",
    "        \n",
    "        param U1 {I, I};\n",
    "        param U2 {I, I};\n",
    "        param M{P};\n",
    "        \n",
    "        var s1 {I} >= 0;\n",
    "        var s2 {I} >= 0;\n",
    "        var b1 {I} binary;\n",
    "        var b2 {I} binary;\n",
    "        var v{P};\n",
    "        \n",
    "        subject to cons1_1{i in I}: s1[i] - b1[i] <= 0;\n",
    "        subject to cons1_2{i in I}: s2[i] - b2[i] <= 0;\n",
    "        \n",
    "        subject to cons2_1{i in I}: v[1] - sum{j in I} (U1[i,j] * s2[j]) - M[1]*(1-b1[i]) <= 0;\n",
    "        subject to cons2_2{j in I}: v[2] - sum{i in I} (U2[i,j] * s1[i]) - M[2]*(1-b2[j]) <= 0;\n",
    "        \n",
    "        subject to cons3_1{i in I}: v[1] - sum{j in I} (U1[i,j] * s2[j]) >= 0;\n",
    "        subject to cons3_2{j in I}: v[2] - sum{i in I} (U2[i,j] * s1[i]) >= 0;\n",
    "        \n",
    "        subject to sumToOne_1: sum{i in I} s1[i] == 1;\n",
    "        subject to sumToOne_2: sum{j in I} s2[j] == 1;\n",
    "        \n",
    "        maximize obj: v[1] + v[2];\n",
    "    \"\"\")\n",
    "\n",
    "    ampl.set['P'] = P\n",
    "    ampl.set['I'] = I\n",
    "\n",
    "    U_df = {player: pd.DataFrame(U[player], index=I, columns=I) for player in P}\n",
    "    \n",
    "    for player in P:\n",
    "        ampl.param['U' + str(player)] = U_df[player]\n",
    "\n",
    "    ampl.param['M'] = {player: 1000 for player in P}\n",
    "\n",
    "    # AMPL solver\n",
    "    ampl.solve(solver='gurobi')\n",
    "    assert ampl.solve_result == \"solved\"\n",
    "    ampl.display('v', 's1', 's2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two actions game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi 9.5.1: optimal solution; objective 3\n",
      "16 simplex iterations\n",
      "1 branch-and-cut nodes\n",
      "plus 8 simplex iterations for intbasis\n",
      ":     v    s1    s2     :=\n",
      "1    1.5    .     .\n",
      "2    1.5    .     .\n",
      "a1    .    0.5   0.5\n",
      "a2    .    0.5   0.5\n",
      "a3    .    0     0\n",
      ";\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "I = [\"a1\", \"a2\", \"a3\"]\n",
    "P = [1, 2]\n",
    "\n",
    "\n",
    "U1 = [[2,1,0], \n",
    "    [1,2,0],\n",
    "    [0,0,0]]\n",
    "\n",
    "U2 = [[1,2,0], \n",
    "    [2,1,0],\n",
    "    [0,0,0]]\n",
    "\n",
    "nash_equilibrium(players=P, actions=I, U1 = U1, U2 = U2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
